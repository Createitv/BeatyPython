## 1. 线程介绍

目前，在软件应用中使用最广泛的并发编程范例是多线程。通常，一个应用有一个进程，分成多个独立的线程，并行运行、互相配合，执行不同类型的任务。

主要特点：

- 线程是独立的处理流程，可以和系统的其他线程并行或并发地执行。
- 多线程可以共享数据和资源，利用所谓的共享内存空间。
- 同一进程的多个不同的线程可以共享相同的资源。相比而言，进程之间不会共享资源。

每一个线程基本上包含3个元素：程序计数器，寄存器和栈。与同一进程的其他线程共享的资源基本上包括数据和系统资源。每一个线程也有自己的运行状态，可以和其他线程同步，这点和进程一样。线程的状态大体上可以分为**ready**,**running**,**blocked**。

## 2. python线程模块介绍

Python通过标准库的 `threading` 模块来管理线程。这个模块提供了很多不错的特性，让线程变得无比简单。实际上，线程模块提供了几种同时运行的机制，实现起来非常简单。

线程模块的主要组件如下：

- 线程对象
- Lock对象
- RLock对象
- 信号对象
- 条件对象
- 事件对象

## 3. 定义一个python线程

使用线程最简单的一个方法是，用一个目标函数实例化一个Thread然后调用 `start()` 方法启动它。Python的threading模块提供了 `Thread()` 方法在不同的线程中运行函数或处理过程等。

```python
class threading.Thread(group=None,
                       target=None,
                       name=None,
                       args=(),
                       kwargs={})
```

上面的代码中：

- `group`: 一般设置为 `None` ，这是为以后的一些特性预留的
- `target`: 当线程启动的时候要执行的函数
- `name`: 线程的名字，默认会分配一个唯一名字 `Thread-N`
- `args`: 传递给 `target` 的参数，要使用tuple类型
- `kwargs`: 同上，使用字典类型dict

创建线程的方法非常实用，通过`target`参数`arg`和`kwarg`告诉线程应该做什么。下面这个例子传递一个数字给线程（这个数字正好等于线程号码），目标函数会打印出这个数字。

### 3.1 代码举例

```python
import threading

def function(i):
    print ("function called by thread %i\n" % i)
    return

threads = []

for i in range(5):
  	# 线程对象
    t = threading.Thread(target=function , args=(i, ))
    threads.append(t)
    t.start()
    # 加入主线程队列
    t.join()
```

输出

```python
 ✔  python -u thread_simple.py
function called by thread 0

function called by thread 1

function called by thread 2

function called by thread 3

function called by thread 4
```

导入内置threading模块，简单地使用python命令就可以了：

```
import threading
```

在主程序中，我们使用目标函数 `function` 初始化了一个线程对象 `Thread` 。同时还传入了用于打印的一个参数：

```
t = threading.Thread(target=function , args=(i, ))
```

线程被创建之后并不会马上运行，需要手动调用 `start()` ， `join()` 让调用它的线程一直等待直到执行结束（即阻塞调用它的主线程， `t` 线程执行结束，主线程才会继续执行）：

```
t.start()
t.join()
```

## 4. 确定线程运行状态

threading模块提供了一些比较实用的方法或者属性

![image-20210624092547213](https://typora-1300715298.cos.ap-shanghai.myqcloud.com/uPic/image-20210624092547213.png)

```python
import urllib.request
import threading
import logging
import os

logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s-%(levelname)s-%(message)s')
logger = logging.getLogger(__name__)
sites = [
    '<https://www.yahoo.com/>',
    '<http://www.cnn.com>',
    '<http://www.python.org>',
    '<http://www.jython.org>',
    '<http://www.pypy.org>',
    '<http://www.perl.org>',
    '<http://www.cisco.com>',
    '<http://www.facebook.com>',
    '<http://www.twitter.com>',
    "<https://www.youtube.com/>",
    '<http://arstechnica.com/>',
    '<http://www.reuters.com/>',
    '<http://abcnews.go.com/>',
    '<http://www.cnbc.com/>',
]

def getHtml(url):
    page = urllib.request.urlopen(url).read()
    print(url, len(page))

for url in sites:
    threading.Thread(target=getHtml, args=(url,)).start()
logger.info(f'Process ID: {os.getpid()}')
logger.info(f"Main thread {threading.main_thread()}")
logger.info(f'Thread Count: {threading.active_count()}')
for thread in threading.enumerate():
    logger.info(thread)
```

运行结果：

![image-20210624092630425](https://typora-1300715298.cos.ap-shanghai.myqcloud.com/uPic/image-20210624092630425.png)

### 给线程命名

使用参数来确认或命名线程是笨拙且没有必要的。每一个 `Thread` 实例创建的时候都有一个带默认值的名字，并且可以修改。在服务端通常一个服务进程都有多个线程服务，负责不同的操作，这时候命名线程是很实用的

```python
import threading
import time

def first_function():
    print(threading.currentThread().getName() + str(' is Starting '))
    time.sleep(2)
    print (threading.currentThread().getName() + str(' is Exiting '))
    return

def second_function():
    print(threading.currentThread().getName() + str(' is Starting '))
    time.sleep(2)
    print (threading.currentThread().getName() + str(' is Exiting '))
    return

def third_function():
    print(threading.currentThread().getName() + str(' is Starting '))
    time.sleep(2)
    print(threading.currentThread().getName() + str(' is Exiting '))
    return

if __name__ == "__main__":
    t1 = threading.Thread(name='first_function', target=first_function)
    t2 = threading.Thread(name='second_function', target=second_function)
    t3 = threading.Thread(name='third_function', target=third_function)
    t1.start()
    t2.start()
    t3.start()
```

运行结果:

```python
 ✔  python -u thread_simple.py
first_function is Starting 
second_function is Starting 
third_function is Starting 
first_function is Exiting 
second_function is Exiting 
third_function is Exiting 
```

### 解析

我们使用目标函数实例化线程。同时，我们传入 `name` 参数作为线程的名字，如果不传这个参数，将使用默认的参数：

```
t1 = threading.Thread(name='first_function', target=first_function)
t2 = threading.Thread(name='second_function', target=second_function)
t3 = threading.Thread(target=third_function)
```

（译者注：这里的代码和上面的不一样，可能作者本意是第三个线程不加参数来测试默认的行为，如果改为这里的代码，那么线程3将会输出的是 `Thread-1 is Starting` 以及 `Thread-1 is Exiting` ，读者可以自行尝试）

最后调用 `start()` 和 `join()` 启动它们。

```
t1.start()
t2.start()
t3.start()
t1.join()
t2.join()
t3.join()
```

## 5. 自己动手实现一个线程

使用threading模块实现一个新的线程，需要下面3步：

- 定义一个 `Thread` 类的子类
- 重写 `__init__(self [,args])` 方法，可以添加额外的参数
- 最后，需要重写 `run(self, [,args])` 方法来实现线程要做的事情

当你创建了新的 `Thread` 子类的时候，你可以实例化这个类，调用 `start()` 方法来启动它。线程启动之后将会执行 `run()` 方法。

```python
import threading
import time

exitFlag = 0

class myThread (threading.Thread):
    def __init__(self, threadID, name, counter):
        threading.Thread.__init__(self)
        self.threadID = threadID
        self.name = name
        self.counter = counter

    def run(self):
        print("Starting " + self.name)
        print_time(self.name, self.counter, 5)
        print("Exiting " + self.name)

def print_time(threadName, delay, counter):
    while counter:
        if exitFlag:
            # 译者注：原书中使用的thread，但是Python3中已经不能使用thread，以_thread取代，因此应该
            # import _thread
            # _thread.exit()
            thread.exit()
        time.sleep(delay)
        print("%s: %s" % (threadName, time.ctime(time.time())))
        counter -= 1

# Create new threads
thread1 = myThread(1, "Thread-1", 1)
thread2 = myThread(2, "Thread-2", 2)

# Start new Threads
thread1.start()
thread2.start()

# 以下两行为译者添加，如果要获得和图片相同的结果，
# 下面两行是必须的。疑似原作者的疏漏
thread1.join()
thread2.join()
print("Exiting Main Thread")
```

结果：

```python
 ✔  python -u thread_run.py
Starting Thread-1Starting Thread-2

Thread-1: Thu Jun 24 09:31:43 2021
Thread-2: Thu Jun 24 09:31:44 2021Thread-1: Thu Jun 24 09:31:44 2021

Thread-1: Thu Jun 24 09:31:45 2021
Thread-1: Thu Jun 24 09:31:46 2021Thread-2: Thu Jun 24 09:31:46 2021

Thread-1: Thu Jun 24 09:31:47 2021
Exiting Thread-1
Thread-2: Thu Jun 24 09:31:48 2021
Thread-2: Thu Jun 24 09:31:50 2021
Thread-2: Thu Jun 24 09:31:52 2021
Exiting Thread-2
Exiting Main Thread
```

解释：

`threading` 模块是创建和管理线程的首选形式。每一个线程都通过一个继承 `Thread` 类，重写 `run()` 方法来实现逻辑，这个方法是线程的入口。在主程序中，我们创建了多个 `myThread` 的类型实例，然后执行 `start()` 方法启动它们。调用 `Thread.__init__` 构造器方法是必须的，通过它我们可以给线程定义一些名字或分组之类的属性。调用 `start()` 之后线程变为活跃状态，并且持续直到 `run()` 结束，或者中间出现异常。所有的线程都执行完成之后，程序结束。

`join()` 命令控制主线程的终止。

## 6. 线程锁🔒

当两个或以上对共享内存的操作发生在并发线程中，并且至少有一个可以改变数据，又没有同步机制的条件下，就会产生竞争条件，可能会导致执行无效代码、bug、或异常行为。

竞争条件最简单的解决方法是使用锁。锁的操作非常简单，当一个线程需要访问部分共享内存时，它必须先获得锁才能访问。此线程对这部分共享资源使用完成之后，该线程必须释放锁，然后其他线程就可以拿到这个锁并访问这部分资源了。

然而，在实际使用的过程中，我们发现这个方法经常会导致一种糟糕的死锁现象。当不同的线程要求得到一个锁时，死锁就会发生，这时程序不可能继续执行，因为它们互相拿着对方需要的锁。使用锁来解决同步问题是一个可行却存在潜在问题的方案。

### 6.1 代码解释

```python
# -*- coding: utf-8 -*-

import threading

shared_resource_with_lock = 0
shared_resource_with_no_lock = 0
COUNT = 100000
shared_resource_lock = threading.Lock()

# 有锁的情况
def increment_with_lock():
    global shared_resource_with_lock
    for i in range(COUNT):
        shared_resource_lock.acquire()
        shared_resource_with_lock += 1
        shared_resource_lock.release()

def decrement_with_lock():
    global shared_resource_with_lock
    for i in range(COUNT):
        shared_resource_lock.acquire()
        shared_resource_with_lock -= 1
        shared_resource_lock.release()

# 没有锁的情况
def increment_without_lock():
    global shared_resource_with_no_lock
    for i in range(COUNT):
        shared_resource_with_no_lock += 1

def decrement_without_lock():
    global shared_resource_with_no_lock
    for i in range(COUNT):
        shared_resource_with_no_lock -= 1

if __name__ == "__main__":
    t1 = threading.Thread(target=increment_with_lock)
    t2 = threading.Thread(target=decrement_with_lock)
    t3 = threading.Thread(target=increment_without_lock)
    t4 = threading.Thread(target=decrement_without_lock)
    t1.start()
    t2.start()
    t3.start()
    t4.start()
    t1.join()
    t2.join()
    t3.join()
    t4.join()
    print ("the value of shared variable with lock management is %s" % shared_resource_with_lock)
    print ("the value of shared variable with race condition is %s" % shared_resource_with_no_lock)
```

运行结果：

```python
 ✔  python -u thread_lock.py
the value of shared variable with lock management is 0
the value of shared variable with race condition is 67058
```

可以看出，如果有锁来管理线程的话，我们会得到正确的结果。这里要注意，没有锁的情况下并不一定会得到错误的结果，但是重复执行多次，总会出现错误的结果。而有锁的情况结果总会是正确的。

### 6.2 代码解释

在主程序中，我们有以下步骤：

```
t1 = threading.Thread(target=increment_with_lock)
t2 = threading.Thread(target=decrement_with_lock)
```

启动线程：

```
t1.start()
t2.start()
```

然后阻塞主线程直到所有线程完成：

```
t1.join()
t2.join()
```

在 `increment_with_lock()` 函数和 `decrement_with_lock()` 函数中，可以看到我们使用了lock语句。当你需要使用资源的时候，调用 `acquire()` 拿到锁（如果锁暂时不可用，会一直等待直到拿到），最后调用 `release()`:

```
shared_resource_lock.acquire()
shared_resource_with_lock -= 1
shared_resource_lock.release()
```

让我们总结一下：

- 锁有两种状态： locked（被某一线程拿到）和unlocked（可用状态）
- 我们有两个方法来操作锁： `acquire()` 和 `release()`

需要遵循以下规则：

- 如果状态是unlocked， 可以调用 `acquire()` 将状态改为locked
- 如果状态是locked， `acquire()` 会被block直到另一线程调用 `release()` 释放锁
- 如果状态是unlocked， 调用 `release()` 将导致 `RuntimError` 异常
- 如果状态是locked， 可以调用 `release()` 将状态改为unlocked

### 6.3. 线程弊端

尽管理论上行得通，但是锁的策略不仅会导致有害的僵持局面。还会对应用程序的其他方面产生负面影响。这是一种保守的方法，经常会引起不必要的开销，也会限制程序的可扩展性和可读性。更重要的是，有时候需要对多进程共享的内存分配优先级，使用锁可能和这种优先级冲突。最后，从实践的经验来看，使用锁的应用将对debug带来不小的麻烦。所以，最好使用其他可选的方法确保同步读取共享内存，避免竞争条件。

## 7. 递归锁RLOCK

RLock其实叫做“Reentrant Lock”，就是可以重复进入的锁，也叫做“递归锁”。这种锁对比Lock有是三个特点：1. 谁拿到谁释放。如果线程A拿到锁，线程B无法释放这个锁，只有A可以释放；2. 同一线程可以多次拿到该锁，即可以acquire多次；3. acquire多少次就必须release多少次，只有最后一次release才能改变RLock的状态为unlocked

如果是一把互斥锁（threading.Lock()），那么下面的代码会发生堵塞：

```python
import threading
lock = threading.Lock()

lock.acquire()
    for i in range(10):
        print('获取第二把锁')
        lock.acquire()
        print(f'test.......{i}')
        lock.release()
    lock.release()

```

同样的代码，如果换成（threading.RLock()），则不会发生堵塞：

```python
import threading
lock = threading.RLock()

lock.acquire()
    for i in range(10):
        print('获取第二把锁')
        lock.acquire()
        print(f'test.......{i}')
        lock.release()
    lock.release()
```

**RLock其实底层维护了一个互斥锁和一个计数器**

## 8. 信号量

**信号量也是一把锁，用来控制线程并发数的**。BoundedSemaphore或Semaphore管理一个内置的计数 器，每当调用acquire()时-1，调用release()时+1。

计数器不能小于0，当计数器为 0时，acquire()将阻塞线程至同步锁定状态，直到其他线程调用release()。(类似于停车位的概念)

类名：BoundedSemaphore。这种锁允许一定数量的线程同时更改数据，它不是互斥锁。比如地铁安检，排队人很多，工作人员只允许一定数量的人进入安检区，其它的人继续排队。

同样的，在threading模块中，信号量的操作有两个函数，即 `acquire()` 和 `release()` ，解释如下：

- 每当线程想要读取关联了信号量的共享资源时，必须调用 `acquire()` ，此操作减少信号量的内部变量, 如果此变量的值非负，那么分配该资源的权限。如果是负值，那么线程被挂起，直到有其他的线程释放资源。
- 当线程不再需要该共享资源，必须通过 `release()` 释放。这样，信号量的内部变量增加，在信号量等待队列中排在最前面的线程会拿到共享资源的权限。

![../_images/semaphores.png](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/semaphores.png)

### 8.1 代码

```python
import time
import threading


def run(n, se):
    se.acquire()
    print("run the thread: %s" % n)
    time.sleep(1)
    se.release()


# 设置允许5个线程同时运行
semaphore = threading.BoundedSemaphore(5)
for i in range(20):
    t = threading.Thread(target=run, args=(i, semaphore))
    t.start()
```

运行结果：

​	![BoundedSemaphore](https://typora-1300715298.cos.ap-shanghai.myqcloud.com/uPic/image-20210624101949016.png)

### 8.2 消费者模型的信号量使用

```python
# -*- coding: utf-8 -*-

"""Using a Semaphore to synchronize threads"""
import threading
import time
import random

# The optional argument gives the initial value for the internal
# counter;
# it defaults to 1.
# If the value given is less than 0, ValueError is raised.
semaphore = threading.Semaphore(0)

def consumer():
        print("consumer is waiting.")
        # Acquire a semaphore
        semaphore.acquire()
        # The consumer have access to the shared resource
        print("Consumer notify : consumed item number %s " % item)

def producer():
        global item
        time.sleep(10)
        # create a random item
        item = random.randint(0, 1000)
        print("producer notify : produced item number %s" % item)
         # Release a semaphore, incrementing the internal counter by one.
        # When it is zero on entry and another thread is waiting for it
        # to become larger than zero again, wake up that thread.
        semaphore.release()

if __name__ == '__main__':
        for i in range (0,5) :
                t1 = threading.Thread(target=producer)
                t2 = threading.Thread(target=consumer)
                t1.start()
                t2.start()
                t1.join()
                t2.join()
        print("program terminated")
```

我们使用生产者-消费者模型展示通过信号量的同步。当生产者生产出item，便释放信号量。然后消费者拿到资源进行消费。

运行结果：

```python
 ↵  python -u thread_semaphore.py
consumer is waiting.
producer notify : produced item number 328
Consumer notify : consumed item number 328 
consumer is waiting.
producer notify : produced item number 230
Consumer notify : consumed item number 230 
consumer is waiting.
producer notify : produced item number 174
Consumer notify : consumed item number 174 
consumer is waiting.
producer notify : produced item number 573
Consumer notify : consumed item number 573 
consumer is waiting.
producer notify : produced item number 286
Consumer notify : consumed item number 286 
program terminated
```

## 9. 条件线程设置

条件指的是应用程序状态的改变。这是另一种同步机制，其中某些线程在等待某一条件发生，其他的线程会在该条件发生的时候进行通知。一旦条件发生，线程会拿到共享资源的唯一权限。

### 9.1 代码

```python
from threading import Thread, Condition
import time

items = []
condition = Condition()

class consumer(Thread):

    def __init__(self):
        Thread.__init__(self)

    def consume(self):
        global condition
        global items
        condition.acquire()
        if len(items) == 0:
            condition.wait()
            print("Consumer notify : no item to consume")
        items.pop()
        print("Consumer notify : consumed 1 item")
        print("Consumer notify : items to consume are " + str(len(items)))

        condition.notify()
        condition.release()

    def run(self):
        for i in range(0, 20):
            time.sleep(2)
            self.consume()

class producer(Thread):

    def __init__(self):
        Thread.__init__(self)

    def produce(self):
        global condition
        global items
        condition.acquire()
        if len(items) == 10:
            condition.wait()
            print("Producer notify : items producted are " + str(len(items)))
            print("Producer notify : stop the production!!")
        items.append(1)
        print("Producer notify : total items producted " + str(len(items)))
        condition.notify()
        condition.release()

    def run(self):
        for i in range(0, 20):
            time.sleep(1)
            self.produce()

if __name__ == "__main__":
    producer = producer()
    consumer = consumer()
    producer.start()
    consumer.start()
    producer.join()
    consumer.join()
```

运行结果：

![../_images/Page-75-Image-12.png](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/Page-75-Image-12.png)

(译者在这里添加一段。乍一看这段代码好像会死锁，因为 `condition.acquire()` 之后就在 `.wait()` 了，好像会一直持有锁。其实 `.wait()` 会将锁释放，然后等待其他线程 `.notify()` 之后会重新尝试获得锁。但是要注意 `.notify()` 并不会自动释放锁，所以代码中有两行，先 `.notify()` 然后再 `.release()` 。

译者画了一张图，方便大家理解。这里的过程应该是这样子的（注意 `wait()` 里面实际有一个释放锁重新获得锁的过程）：

![../_images/python-condition.png](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/python-condition.png)

译者的私货完毕，建议看一下官方文档： https://docs.python.org/3/library/threading.html )

消费者通过拿到锁来修改共享的资源 `items[]` ：

```
condition.acquire()
```

如果list的长度为0，那么消费者就进入等待状态：

```
if len(items) == 0:
    condition.wait()
```

否则就通过 `pop` 操作消费一个item：

```
items.pop()
```

然后，消费者的状态被通知给生产者，同时共享资源释放：

```
condition.notify()
condition.release()
```

生产者拿到共享资源，然后确认缓冲队列是否已满（在我们的这个例子中，最大可以存放10个item），如果已经满了，那么生产者进入等待状态，直到被唤醒：

```
condition.acquire()
if len(items) == 10:
    condition.wait()
```

如果队列没有满，就生产1个item，通知状态并释放资源：

```
condition.notify()
condition.release()
```

## 10. 事件进行线程同步

事件是线程之间用于通讯的对象。有的线程等待信号，有的线程发出信号。基本上事件对象都会维护一个内部变量，可以通过 `set()` 方法设置为 `true` ，也可以通过 `clear()` 方法设置为 `false` 。 `wait()` 方法将会阻塞线程，直到内部变量为 `true` 。

### 10.1 代码

```python
import time
from threading import Thread, Event
import random
items = []
event = Event()

class consumer(Thread):
    def __init__(self, items, event):
        Thread.__init__(self)
        self.items = items
        self.event = event

    def run(self):
        while True:
            time.sleep(2)
            self.event.wait()
            item = self.items.pop()
            print('Consumer notify : %d popped from list by %s' % (item, self.name))

class producer(Thread):
    def __init__(self, items, event):
        Thread.__init__(self)
        self.items = items
        self.event = event

    def run(self):
        global item
        for i in range(100):
            time.sleep(2)
            item = random.randint(0, 256)
            self.items.append(item)
            print('Producer notify : item N° %d appended to list by %s' % (item, self.name))
            print('Producer notify : event set by %s' % self.name)
            self.event.set()
            print('Produce notify : event cleared by %s '% self.name)
            self.event.clear()

if __name__ == '__main__':
    t1 = producer(items, event)
    t2 = consumer(items, event)
    t1.start()
    t2.start()
    t1.join()
    t2.join()

```

线程t1在list最后添加值，然后设置event来通知消费者。消费者通过 `wait()` 阻塞，直到收到信号的时候从list中取出元素消费。

运行结果：

![../_images/Page-78-Image-13.png](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/Page-78-Image-13.png)

解释：

`producer` 类初始化时定义了item的list和 `Event` ，与条件对象时候的例子不同，这里的list并不是全局的，而是通过参数传入的：

```
class consumer(Thread):
    def __init__(self, items, event):
        Thread.__init__(self)
        self.items = items
        self.event = event
```

在run方法中，每当item创建， `producer` 类将新item添加到list末尾然后发出事件通知。使用事件有两步，第一步：

```
self.event.set()
```

第二步：

```
self.event.clear()
```

`consumer` 类初始化时也定义了item的list和 `Event()` 。当item进来的时候，它将其取出：

```
def run(self):
    while True:
        time.sleep(2)
        self.event.wait()
        item = self.items.pop()
        print('Consumer notify : %d popped from list by %s' % (item, self.name))
```

下图可以帮我们认识 `producer` 和 `consumer` ：

![../_images/event.png](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/event.png)

## 11. 线程中的with语句

Python从2.5版本开始引入了 `with` 语法。此语法非常实用，在有两个相关的操作需要在一部分代码块前后分别执行的时候，可以使用 `with` 语法自动完成。同事，使用 `with` 语法可以在特定的地方分配和释放资源，因此， `with` 语法也叫做“上下文管理器”。在threading模块中，所有带有 `acquire()` 方法和 `release()` 方法的对象都可以使用上下文管理器。

也就是说，下面的对象可以使用 `with` 语法：

- Lock
- RLock
- Condition
- Semaphore

### 11.1 代码

```python
import threading
import logging
logging.basicConfig(level=logging.DEBUG, format='(%(threadName)-10s) %(message)s',)

def threading_with(statement):
    with statement:
        logging.debug('%s acquired via with' % statement)

def threading_not_with(statement):
    statement.acquire()
    try:
        logging.debug('%s acquired directly' % statement )
    finally:
        statement.release()

if __name__ == '__main__':
    # let's create a test battery
    lock = threading.Lock()
    rlock = threading.RLock()
    condition = threading.Condition()
    mutex = threading.Semaphore(1)
    threading_synchronization_list = [lock, rlock, condition, mutex]
    # in the for cycle we call the threading_with e threading_no_with function
    for statement in threading_synchronization_list :
       t1 = threading.Thread(target=threading_with, args=(statement,))
       t2 = threading.Thread(target=threading_not_with, args=(statement,))
       t1.start()
       t2.start()
       t1.join()
       t2.join()
```

运行结果:

```python
↵ python -u thread_with.py
(Thread-1  ) <locked _thread.lock object at 0x1019a1450> acquired via with
(Thread-2  ) <locked _thread.lock object at 0x1019a1450> acquired directly
(Thread-3  ) <locked _thread.RLock object owner=123145583611904 count=1 at 0x1019a1420> acquired via with
(Thread-4  ) <locked _thread.RLock object owner=123145583611904 count=1 at 0x1019a1420> acquired directly
(Thread-5  ) <Condition(<locked _thread.RLock object owner=123145583611904 count=1 at 0x1019a19c0>, 0)> acquired via with
(Thread-6  ) <Condition(<locked _thread.RLock object owner=123145600401408 count=1 at 0x1019a19c0>, 0)> acquired directly
(Thread-7  ) <threading.Semaphore object at 0x101818910> acquired via with
(Thread-8  ) <threading.Semaphore object at 0x101818910> acquired directly
```

### 10.2 解释

在主程序中，我们定义了一个list， `threading_synchronization_list` ，包含要测试的线程同步使用的对象：

```
lock = threading.Lock()
rlock = threading.RLock()
condition = threading.Condition()
mutex = threading.Semaphore(1)
threading_synchronization_list = [lock, rlock, condition, mutex]
```

定义之后，我们可以在 `for` 循环中测试每一个对象：

```
for statement in threading_synchronization_list :
   t1 = threading.Thread(target=threading_with, args=(statement,))
   t2 = threading.Thread(target=threading_not_with, args=(statement,))
```

最后，我们有两个目标函数，其中 `threading_with` 测试了 `with` 语法：

```
def threading_with(statement):
    with statement:
        logging.debug('%s acquired via with' % statement)
```

## 12. 使用队列进行线程通信

当线程之间如果要共享资源或数据的时候，可能变的非常复杂。如你所见，Python的threading模块提供了很多同步原语，包括信号量，条件变量，事件和锁。如果可以使用这些原语的话，应该优先考虑使用这些，而不是使用queue（队列）模块。队列操作起来更容易，也使多线程编程更安全，因为队列可以将资源的使用通过单线程进行完全控制，并且允许使用更加整洁和可读性更高的设计模式。

Queue常用的方法有以下四个：

- `put()`: 往queue中放一个item
- `get()`: 从queue删除一个item，并返回删除的这个item
- `task_done()`: 每次item被处理的时候需要调用这个方法
- `join()`: 所有item都被处理之前一直阻塞

### 12.2 代码

```python
from threading import Thread, Event
from queue import Queue
import time
import random
class producer(Thread):
    def __init__(self, queue):
        Thread.__init__(self)
        self.queue = queue

    def run(self) :
        for i in range(10):
            item = random.randint(0, 256)
            self.queue.put(item)
            print('Producer notify: item N° %d appended to queue by %s' % (item, self.name))
            time.sleep(1)

class consumer(Thread):
    def __init__(self, queue):
        Thread.__init__(self)
        self.queue = queue

    def run(self):
        while True:
            item = self.queue.get()
            print('Consumer notify : %d popped from queue by %s' % (item, self.name))
            self.queue.task_done()

if __name__ == '__main__':
    queue = Queue()
    t1 = producer(queue)
    t2 = consumer(queue)
    t3 = consumer(queue)
    t4 = consumer(queue)
    t1.start()
    t2.start()
    t3.start()
    t4.start()
    t1.join()
    t2.join()
    t3.join()
    t4.join()
```

运行结果：

![../_images/Page-85-Image-15.png](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/Page-85-Image-15.png)

### 12.2 解释

首先，我们创建一个生产者类。由于我们使用队列存放数字，所以不需要用来存放数字的list了。

```
class producer(Thread):
    def __init__(self, queue):
        Thread.__init__(self)
        self.queue = queue
```

`producer` 类生产整数，然后通过一个 `for` 循环将整数放到队列中：

```
def run(self) :
    for i in range(10):
        item = random.randint(0, 256)
        self.queue.put(item)
        print('Producer notify: item N° %d appended to queue by %s' % (item, self.name))
        time.sleep(1)
```

生产者使用 `Queue.put(item [,block[, timeout]])` 来往queue中插入数据。Queue是同步的，在插入数据之前内部有一个内置的锁机制。

可能发生两种情况：

- 如果 `block` 为 `True` ， `timeout` 为 `None` （这也是默认的选项，本例中使用默认选项），那么可能会阻塞掉，直到出现可用的位置。如果 `timeout` 是正整数，那么阻塞直到这个时间，就会抛出一个异常。
- 如果 `block` 为 `False` ，如果队列有闲置那么会立即插入，否则就立即抛出异常（ `timeout` 将会被忽略）。本例中， `put()` 检查队列是否已满，然后调用 `wait()` 开始等待。

消费者从队列中取出整数然后用 `task_done()` 方法将其标为任务已处理。

消费者使用 `Queue.get([block[, timeout]])` 从队列中取回数据，queue内部也会经过锁的处理。如果队列为空，消费者阻塞。

最后，在主程序中，我们创建线程t作为生产者，t1, t2, t3作为消费者：

```
if __name__ == '__main__':
    queue = Queue()
    t1 = producer(queue)
    t2 = consumer(queue)
    t3 = consumer(queue)
    t4 = consumer(queue)
    t1.start()
    t2.start()
    t3.start()
    t4.start()
    t1.join()
    t2.join()
    t3.join()
    t4.join()
```

生产者和消费者之间的操作可以用下图来描述：

![../_images/queue.png](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/queue.png)

## 13. 评估多线程应用的性能

在本节中，我们将验证GIL的影响，评估多线程应用的性能。前文已经介绍过，GIL是CPython解释器引入的锁，GIL在解释器层面阻止了真正的并行运行。解释器在执行任何线程之前，必须等待当前正在运行的线程释放GIL。事实上，解释器会强迫想要运行的线程必须拿到GIL才能访问解释器的任何资源，例如栈或Python对象等。这也正是GIL的目的——阻止不同的线程并发访问Python对象。这样GIL可以保护解释器的内存，让垃圾回收工作正常。但事实上，这却造成了程序员无法通过并行执行多线程来提高程序的性能。如果我们去掉CPython的GIL，就可以让多线程真正并行执行。GIL并没有影响多处理器并行的线程，只是限制了一个解释器只能有一个线程在运行。

### 13.1 代码

下面的代码是用来评估多线程应用性能的简单工具。下面的每一个测试都循环调用函数100次，重复执行多次，取速度最快的一次。在 `for` 循环中，我们调用 `non_threaded` 和 `threaded` 函数。同时，我们会不断增加调用次数和线程数来重复执行这个测试。我们会尝试使用1，2，3，4和8线程数来调用线程。在非线程的测试中，我们顺序调用函数与对应线程数一样多的次数。为了保持简单，度量的指标使用Python的内建模块timer。

代码如下：

```python
from threading import Thread

class threads_object(Thread):
    def run(self):
        function_to_run()

class nothreads_object(object):
    def run(self):
        function_to_run()

def non_threaded(num_iter):
    funcs = []
    for i in range(int(num_iter)):
        funcs.append(nothreads_object())
    for i in funcs:
        i.run()

def threaded(num_threads):
    funcs = []
    for i in range(int(num_threads)):
        funcs.append(threads_object())
    for i in funcs:
        i.start()
    for i in funcs:
        i.join()

def function_to_run():
    pass

def show_results(func_name, results):
    print("%-23s %4.6f seconds" % (func_name, results))

if __name__ == "__main__":
    import sys
    from timeit import Timer
    repeat = 100
    number = 1
    num_threads = [1, 2, 4, 8]
    print('Starting tests')
    for i in num_threads:
        t = Timer("non_threaded(%s)" % i, "from __main__ import non_threaded")
        best_result = min(t.repeat(repeat=repeat, number=number))
        show_results("non_threaded (%s iters)" % i, best_result)
        t = Timer("threaded(%s)" % i, "from __main__ import threaded")
        best_result = min(t.repeat(repeat=repeat, number=number))
        show_results("threaded (%s threads)" % i, best_result)
        print('Iterations complete')
```

## 13.2. 解释

我们一共进行了四次测试(译者注：原文是three，我怀疑原作者不识数，原文的3个线程数也没有写在代码里），每一次都会使用不同的function进行测试，只要改变 `function_to_run()` 就可以了。

测试用的机器是 Core 2 Duo CPU – 2.33Ghz。

### 第一次测试

在第一次测试中，我们使用了一个简单的空函数：

```
def function_to_run():
    pass
```

下图展示了我们测试的每个机制的运行速度：

![test1](https://typora-1300715298.cos.ap-shanghai.myqcloud.com/uPic/image-20210624105756890.png)

通过结果可以发现，使用线程的开销要比不使用线程的开销大的多。特别的，我们发现随着线程的数量增加，带来的开销是成比例的。4个线程的运行时间是0.000162秒，8个线程的运行时间是0.000316秒。

### 第二次测试

多线程比较常用的一个用途是处理数字，下面的测试计算斐波那契数列，注意这个例子中没有共享的资源，只是测试生成数字数列：

```
def function_to_run():
    a, b = 0, 1
    for i in range(10000):
        a, b = b, a + b
```

输出如下：

![image-20210624105829147](https://typora-1300715298.cos.ap-shanghai.myqcloud.com/uPic/image-20210624105829147.png)

在输出中可以看到，提高线程的数量并没有带来收益。因为GIL和线程管理代码的开销，多线程运行永远不可能比函数顺序执行更快。再次提醒一下：GIL只允许解释器一次执行一个线程。

### 第三次测试

下面的测试是读1kb的数据1000次，测试用的函数如下：

```
def function_to_run():
    fh=open("C:\\CookBookFileExamples\\test.dat","rb")
    size = 1024
    for i in range(1000):
        fh.read(size)
```

测试的结果如下：

![../_images/Page-92-Image-18.png](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/Page-92-Image-18.png)

我们终于看到多线程比非多线程跑的好的情况了，而且多线程只用了一半的时间。这给我们的启示是，多线程并不是一个标准。一般，我们将会将多线程放入一个队列中，将它们放到一边，执行其他任务。使用多线程执行同一个相同的任务有时候很有用，但用到的时候很少，除非需要大量处理数据输入。

### 第四次测试

在最后的测试中，我们使用 `urllib.request` 测试，这是一个Python模块，可以发送URL请求。此模块基于 `socket` ，使用C语言编写并且是线程安全的。

下面的代码尝试读取 `https://www.packpub.com` 的主页并且读取前1k的数据：

```
def function_to_run():
    import urllib.request
    for i in range(10):
        with urllib.request.urlopen("https://www.packtpub.com/")as f:
            f.read(1024)
```

运行结果如下：

![../_images/Page-93-Image-19.png](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/Page-93-Image-19.png)

可以看到，在 I/O 期间，GIL释放了。多线程执行比单线程快的多。鉴于大多数应用需要很多I/O操作，GIL并没有限制程序员在这方面使用多线程对程序进行性能优化。

## 13.3. 了解更多

你应该记住，增加线程并不会提高应用启动的时间，但是可以支持并发。例如，一次性创建一个线程池，并重用worker会很有用。这可以让我们切分一个大的数据集，用同样的函数处理不同的部分（生产者消费者模型）。上面这些测试并不是并发应用的模型，只是尽量简单的测试。那么GIL会成为试图发挥多线程应用潜能的纯Python开发的瓶颈吗？是的。线程是编程语言的架构，CPython解释器是线程和操作系统的桥梁。这就是为什么Jython，IronPython没有GIL的原因（译者注：Pypy也没有），因为它不是必要的。

